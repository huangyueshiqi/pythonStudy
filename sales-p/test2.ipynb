{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import loadtxt\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from xgboost import plot_tree\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "kernel_with_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    sales_train = pd.read_csv('sales_train.csv')\n",
    "    items = pd.read_csv('items.csv')\n",
    "    shops = pd.read_csv('shops.csv')\n",
    "    item_categories = pd.read_csv('item_categories.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    # For every month we create a grid from all shops/items combinations from that month\n",
    "    grid = []\n",
    "    for block_num in sales_train['date_block_num'].unique():\n",
    "        cur_shops = sales_train[sales_train['date_block_num']==block_num]['shop_id'].unique()\n",
    "        cur_items = sales_train[sales_train['date_block_num']==block_num]['item_id'].unique()\n",
    "        grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "    index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "    grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "    # Aggregations\n",
    "    sales_train['item_cnt_day'] = sales_train['item_cnt_day'].clip(0,20)\n",
    "    groups = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'])\n",
    "    trainset = groups.agg({'item_cnt_day':'sum', 'item_price':'mean'}).reset_index()\n",
    "    trainset = trainset.rename(columns = {'item_cnt_day' : 'item_cnt_month'})\n",
    "    trainset['item_cnt_month'] = trainset['item_cnt_month'].clip(0,20)\n",
    "\n",
    "    trainset = pd.merge(grid,trainset,how='left',on=index_cols)\n",
    "    trainset.item_cnt_month = trainset.item_cnt_month.fillna(0)\n",
    "\n",
    "    # Get category id\n",
    "    trainset = pd.merge(trainset, items[['item_id', 'item_category_id']], on = 'item_id')\n",
    "    trainset.to_csv('trainset_with_grid.csv')\n",
    "\n",
    "    trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    prev_month_selector = (trainset.month == 10) & (trainset.year == 2015)\n",
    "    train_subset = trainset[prev_month_selector]\n",
    "    groups = train_subset[['shop_id', 'item_id', 'item_cnt_month']].groupby(by = ['shop_id', 'item_id'])\n",
    "    train_subset = groups.agg({'item_cnt_month':'sum'}).reset_index()\n",
    "    train_subset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    merged = test.merge(train_subset, on=[\"shop_id\", \"item_id\"], how=\"left\")[[\"ID\", \"item_cnt_month\"]]\n",
    "    merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    merged['item_cnt_month'] = merged.item_cnt_month.fillna(0).clip(0,20)\n",
    "    submission = merged.set_index('ID')\n",
    "    submission.to_csv('benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    # Extract features and target we want\n",
    "    baseline_features = ['shop_id', 'item_id', 'item_category_id', 'date_block_num', 'item_cnt_month']\n",
    "    train = trainset[baseline_features]\n",
    "    # Remove pandas index column\n",
    "    train = train.set_index('shop_id')\n",
    "    train.item_cnt_month = train.item_cnt_month.astype(int)\n",
    "    train['item_cnt_month'] = train.item_cnt_month.fillna(0).clip(0,20)\n",
    "    # Save train set to file\n",
    "    train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    dataset = loadtxt('train.csv', delimiter=\",\" ,skiprows=1, dtype = int)\n",
    "    trainx = dataset[:, 0:4]\n",
    "    trainy = dataset[:, 4]\n",
    "\n",
    "    test_dataset = loadtxt('test.csv', delimiter=\",\" ,skiprows=1, usecols = (1,2), dtype=int)\n",
    "    test_df = pd.DataFrame(test_dataset, columns = ['shop_id', 'item_id'])\n",
    "\n",
    "    # Make test_dataset pandas data frame, add category id and date block num, then convert back to numpy array and predict\n",
    "    merged_test = pd.merge(test_df, items, on = ['item_id'])[['shop_id','item_id','item_category_id']]\n",
    "    merged_test['date_block_num'] = 33\n",
    "    merged_test.set_index('shop_id')\n",
    "    merged_test.head(3)\n",
    "\n",
    "    model = xgb.XGBRegressor(max_depth = 10, min_child_weight=0.5, subsample = 1, eta = 0.3, num_round = 1000, seed = 1)\n",
    "    model.fit(trainx, trainy, eval_metric='rmse')\n",
    "    preds = model.predict(merged_test.values)\n",
    "\n",
    "    df = pd.DataFrame(preds, columns = ['item_cnt_month'])\n",
    "    df['ID'] = df.index\n",
    "    df = df.set_index('ID')\n",
    "    df.to_csv('simple_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    # Set seeds and options\n",
    "    np.random.seed(10)\n",
    "    pd.set_option('display.max_rows', 231)\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "\n",
    "    # Feature engineering list\n",
    "    new_features = []\n",
    "    enable_feature_idea = [True, True, True, True, True, True, True, True, True, True]\n",
    "\n",
    "    # Some parameters(maybe add more periods, score will be better) [1,2,3,12]\n",
    "    lookback_range = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "    tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    current = time.time()\n",
    "\n",
    "    trainset = pd.read_csv('trainset_with_grid.csv')\n",
    "    items = pd.read_csv('items.csv')\n",
    "    shops = pd.read_csv('shops.csv')\n",
    "\n",
    "\n",
    "    # Only use more recent data\n",
    "    start_month = 0\n",
    "    end_month = 33\n",
    "    trainset = trainset[['shop_id', 'item_id', 'item_category_id', 'date_block_num', 'item_price', 'item_cnt_month']]\n",
    "    trainset = trainset[(trainset.date_block_num >= start_month) & (trainset.date_block_num <= end_month)]\n",
    "\n",
    "    print('Loading test set...')\n",
    "    test_dataset = loadtxt('test.csv', delimiter=\",\" ,skiprows=1, usecols = (1,2), dtype=int)\n",
    "    testset = pd.DataFrame(test_dataset, columns = ['shop_id', 'item_id'])\n",
    "\n",
    "    print('Merging with other datasets...')\n",
    "    # Get item category id into test_df\n",
    "    testset = testset.merge(items[['item_id', 'item_category_id']], on = 'item_id', how = 'left')\n",
    "    testset['date_block_num'] = 34\n",
    "    # Make testset contains same column as trainset so we can concatenate them row-wise\n",
    "    testset['item_cnt_month'] = -1\n",
    "    train_test_set = pd.concat([trainset, testset], axis = 0) \n",
    "\n",
    "    end = time.time()\n",
    "    diff = end - current\n",
    "    print('Took ' + str(int(diff)) + ' seconds to train and predict val set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    item_cat = pd.read_csv('data/item_categories.csv')\n",
    "\n",
    "    # Fix category\n",
    "    l_cat = list(item_cat.item_category_name)\n",
    "    for ind in range(0,1):\n",
    "        l_cat[ind] = 'PC Headsets / Headphones'\n",
    "    for ind in range(1,8):\n",
    "        l_cat[ind] = 'Access'\n",
    "    l_cat[8] = 'Tickets (figure)'\n",
    "    l_cat[9] = 'Delivery of goods'\n",
    "    for ind in range(10,18):\n",
    "        l_cat[ind] = 'Consoles'\n",
    "    for ind in range(18,25):\n",
    "        l_cat[ind] = 'Consoles Games'\n",
    "    l_cat[25] = 'Accessories for games'\n",
    "    for ind in range(26,28):\n",
    "        l_cat[ind] = 'phone games'\n",
    "    for ind in range(28,32):\n",
    "        l_cat[ind] = 'CD games'\n",
    "    for ind in range(32,37):\n",
    "        l_cat[ind] = 'Card'\n",
    "    for ind in range(37,43):\n",
    "        l_cat[ind] = 'Movie'\n",
    "    for ind in range(43,55):\n",
    "        l_cat[ind] = 'Books'\n",
    "    for ind in range(55,61):\n",
    "        l_cat[ind] = 'Music'\n",
    "    for ind in range(61,73):\n",
    "        l_cat[ind] = 'Gifts'\n",
    "    for ind in range(73,79):\n",
    "        l_cat[ind] = 'Soft'\n",
    "    for ind in range(79,81):\n",
    "        l_cat[ind] = 'Office'\n",
    "    for ind in range(81,83):\n",
    "        l_cat[ind] = 'Clean'\n",
    "    l_cat[83] = 'Elements of a food'\n",
    "\n",
    "    lb = preprocessing.LabelEncoder()\n",
    "    item_cat['item_category_id_fix'] = lb.fit_transform(l_cat)\n",
    "    item_cat['item_category_name_fix'] = l_cat\n",
    "    train_test_set = train_test_set.merge(item_cat[['item_category_id', 'item_category_id_fix']], on = 'item_category_id', how = 'left')\n",
    "    _ = train_test_set.drop(['item_category_id'],axis=1, inplace=True)\n",
    "    train_test_set.rename(columns = {'item_category_id_fix':'item_category_id'}, inplace = True)\n",
    "\n",
    "    _ = item_cat.drop(['item_category_id'],axis=1, inplace=True)\n",
    "    _ = item_cat.drop(['item_category_name'],axis=1, inplace=True)\n",
    "\n",
    "    item_cat.rename(columns = {'item_category_id_fix':'item_category_id'}, inplace = True)\n",
    "    item_cat.rename(columns = {'item_category_name_fix':'item_category_name'}, inplace = True)\n",
    "    item_cat = item_cat.drop_duplicates()\n",
    "    item_cat.index = np.arange(0, len(item_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    if enable_feature_idea[0]:\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = 'prev_shopitem_sales_' + str(diff)\n",
    "            trainset2 = train_test_set.copy()\n",
    "            trainset2.loc[:, 'date_block_num'] += diff\n",
    "            trainset2.rename(columns={'item_cnt_month': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(trainset2[['shop_id', 'item_id', 'date_block_num', feature_name]], on = ['shop_id', 'item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            new_features.append(feature_name)\n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    if enable_feature_idea[1]:\n",
    "        groups = train_test_set.groupby(by = ['item_id', 'date_block_num'])\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = 'prev_item_sales_' + str(diff)\n",
    "            result = groups.agg({'item_cnt_month':'mean'})\n",
    "            result = result.reset_index()\n",
    "            result.loc[:, 'date_block_num'] += diff\n",
    "            result.rename(columns={'item_cnt_month': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(result, on = ['item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            new_features.append(feature_name)        \n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    if enable_feature_idea[3]:\n",
    "        groups = train_test_set.groupby(by = ['shop_id', 'item_id', 'date_block_num'])\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = 'prev_shopitem_price_' + str(diff)\n",
    "            result = groups.agg({'item_price':'mean'})\n",
    "            result = result.reset_index()\n",
    "            result.loc[:, 'date_block_num'] += diff\n",
    "            result.rename(columns={'item_price': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(result, on = ['shop_id', 'item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name]\n",
    "            new_features.append(feature_name)        \n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    if enable_feature_idea[3]:\n",
    "        groups = train_test_set.groupby(by = ['item_id', 'date_block_num'])\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = 'prev_item_price_' + str(diff)\n",
    "            result = groups.agg({'item_price':'mean'})\n",
    "            result = result.reset_index()\n",
    "            result.loc[:, 'date_block_num'] += diff\n",
    "            result.rename(columns={'item_price': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(result, on = ['item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name]\n",
    "            new_features.append(feature_name)        \n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mean_encodings(train_test_set, categorical_var_list, target):\n",
    "    feature_name = \"_\".join(categorical_var_list) + \"_\" + target + \"_mean\"\n",
    "\n",
    "    df = train_test_set.copy()\n",
    "    df1 = df[df.date_block_num <= 32]\n",
    "    df2 = df[df.date_block_num <= 33]\n",
    "    df3 = df[df.date_block_num == 34]\n",
    "\n",
    "    # Extract mean encodings using training data(here we don't use month 33 to avoid data leak on validation)\n",
    "    # If I try to extract mean encodings from all months, then val rmse decreases a tiny bit, but test rmse would increase by 4%\n",
    "    # So this is important\n",
    "    mean_32 = df1[categorical_var_list + [target]].groupby(categorical_var_list, as_index=False)[[target]].mean()\n",
    "    mean_32 = mean_32.rename(columns={target:feature_name})\n",
    "\n",
    "    # Extract mean encodings using all data, this will be applied to test data\n",
    "    mean_33 = df2[categorical_var_list + [target]].groupby(categorical_var_list, as_index=False)[[target]].mean()\n",
    "    mean_33 = mean_33.rename(columns={target:feature_name})\n",
    "\n",
    "    # Apply mean encodings\n",
    "    df2 = df2.merge(mean_32, on = categorical_var_list, how = 'left')\n",
    "    df3 = df3.merge(mean_33, on = categorical_var_list, how = 'left')\n",
    "\n",
    "    # Concatenate\n",
    "    train_test_set = pd.concat([df2, df3], axis = 0)\n",
    "    new_features.append(feature_name)\n",
    "    return train_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    create_mean_encodings(train_test_set, ['shop_id', 'item_id'], 'item_cnt_month')\n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    train_test_set = create_mean_encodings(train_test_set, ['item_id'], 'item_cnt_month')\n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_last_sale_shop_item(row):\n",
    "    for diff in range(1,33+1):\n",
    "        feature_name = '_prev_shopitem_sales_' + str(diff)\n",
    "        if row[feature_name] != 0.0:\n",
    "            return diff\n",
    "    return np.nan\n",
    "\n",
    "if kernel_with_output:\n",
    "    lookback_range = list(range(1, 33 + 1))\n",
    "    if enable_feature_idea[6]:\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = '_prev_shopitem_sales_' + str(diff)\n",
    "            trainset2 = train_test_set.copy()\n",
    "            trainset2.loc[:, 'date_block_num'] += diff\n",
    "            trainset2.rename(columns={'item_cnt_month': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(trainset2[['shop_id', 'item_id', 'date_block_num', feature_name]], on = ['shop_id', 'item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            #new_features.append(feature_name)\n",
    "\n",
    "    train_test_set.loc[:, 'last_sale_shop_item'] = train_test_set.progress_apply (lambda row: create_last_sale_shop_item(row),axis=1)\n",
    "    new_features.append('last_sale_shop_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_last_sale_item(row):\n",
    "    for diff in range(1,33+1):\n",
    "        feature_name = '_prev_item_sales_' + str(diff)\n",
    "        if row[feature_name] != 0.0:\n",
    "            return diff\n",
    "    return np.nan\n",
    "if kernel_with_output:\n",
    "    lookback_range = list(range(1, 33 + 1))\n",
    "    if enable_feature_idea[1]:\n",
    "        groups = train_test_set.groupby(by = ['item_id', 'date_block_num'])\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = '_prev_item_sales_' + str(diff)\n",
    "            result = groups.agg({'item_cnt_month':'mean'})\n",
    "            result = result.reset_index()\n",
    "            result.loc[:, 'date_block_num'] += diff\n",
    "            result.rename(columns={'item_cnt_month': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(result, on = ['item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            new_features.append(feature_name)        \n",
    "    train_test_set.loc[:, 'last_sale_item'] = train_test_set.progress_apply (lambda row: create_last_sale_item(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    items_subset = items[['item_id', 'item_name']]\n",
    "    feature_count = 25\n",
    "    tfidf = TfidfVectorizer(max_features=feature_count)\n",
    "    items_df_item_name_text_features = pd.DataFrame(tfidf.fit_transform(items_subset['item_name']).toarray())\n",
    "\n",
    "    cols = items_df_item_name_text_features.columns\n",
    "    for i in range(feature_count):\n",
    "        feature_name = 'item_name_tfidf_' + str(i)\n",
    "        items_subset[feature_name] = items_df_item_name_text_features[cols[i]]\n",
    "        new_features.append(feature_name)\n",
    "\n",
    "    items_subset.drop('item_name', axis = 1, inplace = True)\n",
    "    train_test_set = train_test_set.merge(items_subset, on = 'item_id', how = 'left')\n",
    "    train_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    current = time.time()\n",
    "\n",
    "    baseline_features = ['shop_id', 'item_id', 'item_category_id', 'date_block_num'] +  new_features + ['item_cnt_month']\n",
    "\n",
    "    # Clipping to range 0-20\n",
    "    train_test_set['item_cnt_month'] = train_test_set.item_cnt_month.fillna(0).clip(0,20)\n",
    "\n",
    "    # train: want rows with date_block_num from 0 to 31\n",
    "    train_time_range_lo = (train_test_set['date_block_num'] >= 0)\n",
    "    train_time_range_hi =  (train_test_set['date_block_num'] <= 32)\n",
    "\n",
    "    # val: want rows with date_block_num from 22\n",
    "    validation_time =  (train_test_set['date_block_num'] == 33)\n",
    "\n",
    "    # test: want rows with date_block_num from 34\n",
    "    test_time =  (train_test_set['date_block_num'] == 34)\n",
    "\n",
    "\n",
    "    # Retrieve rows for train set, val set, test set\n",
    "    cv_trainset = train_test_set[train_time_range_lo & train_time_range_hi]\n",
    "    cv_valset = train_test_set[validation_time]\n",
    "    cv_trainset = cv_trainset[baseline_features]\n",
    "    cv_valset = cv_valset[baseline_features]\n",
    "    testset = train_test_set[test_time]\n",
    "    testset = testset[baseline_features]\n",
    "\n",
    "    # Prepare numpy arrays for training/val/test\n",
    "    cv_trainset_vals = cv_trainset.values.astype(int)\n",
    "    trainx = cv_trainset_vals[:, 0:len(baseline_features) - 1]\n",
    "    trainy = cv_trainset_vals[:, len(baseline_features) - 1]\n",
    "\n",
    "    cv_valset_vals = cv_valset.values.astype(int)\n",
    "    valx = cv_valset_vals[:, 0:len(baseline_features) - 1]\n",
    "    valy = cv_valset_vals[:, len(baseline_features) - 1]\n",
    "\n",
    "    testset_vals = testset.values.astype(int)\n",
    "    testx = testset_vals[:, 0:len(baseline_features) - 1]\n",
    "\n",
    "    print('Fitting...')\n",
    "    model = xgb.XGBRegressor(max_depth = 11, min_child_weight=0.5, subsample = 1, eta = 0.3, num_round = 1000, seed = 1, nthread = 16)\n",
    "    model.fit(trainx, trainy, eval_metric='rmse')\n",
    "\n",
    "\n",
    "    preds = model.predict(valx)\n",
    "    # Clipping to range 0-20\n",
    "    preds = np.clip(preds, 0,20)\n",
    "    print('val set rmse: ', sqrt(mean_squared_error(valy, preds)))\n",
    "\n",
    "    preds = model.predict(testx)\n",
    "    # Clipping to range 0-20\n",
    "    preds = np.clip(preds, 0,20)\n",
    "    df = pd.DataFrame(preds, columns = ['item_cnt_month'])\n",
    "    df['ID'] = df.index\n",
    "    df = df.set_index('ID')\n",
    "    df.to_csv('test_preds.csv')\n",
    "    print('test predictions written to file')\n",
    "\n",
    "    end = time.time()\n",
    "    diff = end - current\n",
    "    print('Took ' + str(int(diff)) + ' seconds to train and predict val, test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19eefbc407aa68756bae770c194384c6ab1551afe0862a1394c1038dfe153d80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
