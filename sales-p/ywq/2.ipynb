{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码介绍\n",
    "\n",
    "# *特征处理*\n",
    "- 处理关闭的商店和停售的商品\n",
    "- 融合商店数据集和商品数据集特征\n",
    "- 添加销量特征的历史特征\n",
    "- 对类别特征进行独热编码、类别编码\n",
    "# *模型训练* \n",
    "- 设置训练集验证集测试集\n",
    "- 设置模型参数训练模型\n",
    "- 特征重要性画图\n",
    "- 预测未来销量结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 模型介绍\n",
    "LightGBM（Light Gradient Boosting Machine）是一款基于决策树算法的分布式梯度提升框架。它是一个快速高效、低内存占用、高准确度、支持并行和大规模数据处理的数据科学工具。\n",
    "\n",
    "基本原理是：   \n",
    "* 1. 直方图算法*      \n",
    "先把连续的浮点特征值离散化成  个整数，同时构造一个宽度为  的直方图。在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点。   \n",
    "* 2. 直方图作差加速*   \n",
    "一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到，在速度上可以提升一倍。通常构造直方图时，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的k个桶。在实际构建树的过程中，LightGBM还可以先计算直方图小的叶子节点，然后利用直方图做差来获得直方图大的叶子节点，这样就可以用非常微小的代价得到它兄弟叶子的直方图。   \n",
    "* 3. 带深度限制的按叶子生长策略*   \n",
    "LightGBM采用Leaf-wise的增长策略，该策略每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，Leaf-wise的优点是：在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度；Leaf-wise的缺点是：可能会长出比较深的决策树，产生过拟合。因此LightGBM会在Leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。   \n",
    "* 4. 单边梯度采样算法*    \n",
    "  根据样本的权重信息对样本进行抽样，减少了大量梯度小的样本，但是还能不会过多的改变数据集的分布\n",
    "* 5. 特征值捆绑算法*    \n",
    "  输入：特征F，最大冲突数K，图G；\n",
    "  输出：特征捆绑集合bundles；\n",
    "  （1）构造一个边带有权重的图，其权值对应于特征之间的总冲突；\n",
    "  （2）通过特征在图中的度来降序排序特征；\n",
    "  （3）检查有序列表中的每个特征，并将其分配给具有小冲突的现有bundling（由γγ控制），或创建新bundling。  \n",
    "\n",
    "优点：\n",
    "  1. 速度更快   \n",
    "  LightGBM 采用了直方图算法将遍历样本转变为遍历直方图，极大的降低了时间复杂度；\n",
    "  LightGBM 在训练过程中采用单边梯度算法过滤掉梯度小的样本，减少了大量的计算；\n",
    "  LightGBM 采用了基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；\n",
    "  LightGBM 采用优化后的特征并行、数据并行方法加速计算，当数据量非常大的时候还可以采用投票并行的策略；\n",
    "  LightGBM 对缓存也进行了优化，增加了缓存命中率；\n",
    "\n",
    "2. 内存更小   \n",
    "  使用直方图算法将特征值转变为 bin 值，且不需要记录特征到样本的索引，极大的减少了内存消耗；\n",
    "在训练过程中采用互斥特征捆绑算法减少了特征数量，降低了内存消耗\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.处理关闭的商店和停售的商品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理关闭的商店和停售的商品\n",
    "shop_sales_monthly = filtered.pivot_table(index='date_block_num',\n",
    "                                          columns='shop_id',\n",
    "                                          values='item_cnt_day',\n",
    "                                          fill_value=0,\n",
    "                                          aggfunc=sum)\n",
    "shop_open_month_cnt = (shop_sales_monthly.iloc[-6:] >  0).sum() \n",
    " # 有销量的记录\n",
    "shop_open_month_cnt.head()  \n",
    "# 每个店铺最后半年里有几个月有销量\n",
    "shop_c_n = shop_sales_monthly[shop_open_month_cnt[shop_open_month_cnt < 6].index]\n",
    "shop_c_n.tail(12)\n",
    "# 最后半年经营月数少于6个月的店铺\n",
    "item_selling_month_cnt = (item_sales_monthly.iloc[-6:] >  0).sum() \n",
    "item_selling_month_cnt.head()  # 这些商品在最后半年有几个月有销量\n",
    "open_shop = shop_sales_monthly[shop_open_month_cnt[shop_open_month_cnt == 6].index]\n",
    "open_shop.tail(7) # 最后半年都正常经营的商店\n",
    "item_zero = item_sales_monthly[item_selling_month_cnt[item_selling_month_cnt == 0].index]\n",
    "# 这些商品在最后半年都没有销量\n",
    "item_zero.tail(12)\n",
    "selling_item = item_sales_monthly[item_selling_month_cnt[item_selling_month_cnt > 0].index]\n",
    "selling_item.tail(12)  # 最后半年有销量的商品\n",
    "#只保留最后6个月正常经营的商店和有销售的商品\n",
    "cl_set = filtered[filtered['shop_id'].isin(open_shop.columns) & filtered['item_id'].isin(selling_item.columns)]\n",
    "cl_set\n",
    "#统计月销量\n",
    "from itertools import product\n",
    "import time\n",
    "ts = time.time()\n",
    "martix = []\n",
    "for i in range(34):\n",
    "    record = cl_set[cl_set['date_block_num'] == i]\n",
    "    group = product([i],record.shop_id.unique(),record.item_id.unique())\n",
    "    martix.append(np.array(list(group)))\n",
    "            \n",
    "cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "martix = pd.DataFrame(np.vstack(martix), columns=cols)\n",
    "\n",
    "martix\n",
    "\n",
    "group = filtered.groupby(['date_block_num', 'shop_id', 'item_id']).agg({'item_cnt_day': np.sum})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace=True)\n",
    "group\n",
    "\n",
    "martix = pd.merge(martix, group, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n",
    "martix.head()\n",
    "\n",
    "test['date_block_num'] = 34\n",
    "test['item_cnt_month'] = 0\n",
    "martix = pd.concat([martix.fillna(0), test.drop(columns='ID')], sort=False, ignore_index=True, keys=['date_block_num','shop_id','item_id'])\n",
    "martix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.融合商店数据集和商品数据集特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#融合商店数据集和商品数据集特征\n",
    "martix = martix.merge(shops[['shop_id', 'shop_type_code', 'shop_city_code']], on='shop_id', how='left')\n",
    "martix = martix.merge(items.drop(columns='item_name'), on='item_id', how='left')\n",
    "martix\n",
    "\n",
    "#添加具体的年份和月份\n",
    "martix['year'] =  martix['date_block_num'].map(lambda x: x // 12 + 2013)\n",
    "martix['month'] = martix['date_block_num'].map(lambda x: x % 12)\n",
    "martix.head()\n",
    "\n",
    "# 商品 月销量均值\n",
    "group = martix.groupby(['date_block_num','item_id']).agg({'item_cnt_month':'mean'})\n",
    "group.columns = ['item_cnt_month_avg']\n",
    "group.reset_index(inplace=True)\n",
    "martix = martix.merge(group, on=['date_block_num', 'item_id'], how='left')\n",
    "martix.head()\n",
    "\n",
    "# 商店 月销量均值\n",
    "group = martix.groupby(['date_block_num','shop_id']).agg({'item_cnt_month':'mean'})\n",
    "group.columns = ['shop_cnt_month_avg']\n",
    "group.reset_index(inplace=True)\n",
    "martix = martix.merge(group, on=['date_block_num', 'shop_id'], how='left')\n",
    "martix.head()\n",
    "\n",
    "# 类别 月销量均值\n",
    "group = martix.groupby(['date_block_num','item_category_id']).agg({'item_cnt_month':'mean'})\n",
    "group.columns = ['cat_cnt_month_avg']\n",
    "group.reset_index(inplace=True)\n",
    "martix = martix.merge(group, on=['date_block_num', 'item_category_id'], how='left')\n",
    "martix.head()\n",
    "\n",
    "# 商店-类别 月销量均值\n",
    "group = martix.groupby(['date_block_num','shop_id','item_category_id']).agg({'item_cnt_month':'mean'})\n",
    "group.columns = ['shop_cat_cnt_month_avg']\n",
    "group.reset_index(inplace=True)\n",
    "martix = martix.merge(group, on=['date_block_num','shop_id','item_category_id'], how='left')\n",
    "martix.head()\n",
    "\n",
    "# 大类 月销量均值\n",
    "group = martix.groupby(['date_block_num', 'item_type_code']).agg({'item_cnt_month':'mean'})\n",
    "group.columns = ['itemtype_cnt_month_avg']\n",
    "group.reset_index(inplace=True)\n",
    "martix = martix.merge(group, on=['date_block_num', 'item_type_code'], how='left')\n",
    "martix.head()\n",
    "\n",
    "# 小类 月销量均值\n",
    "group = martix.groupby(['date_block_num', 'sub_type_code']).agg({'item_cnt_month':'mean'})\n",
    "group.columns = ['subtype_cnt_month_avg']\n",
    "group.reset_index(inplace=True)\n",
    "martix = martix.merge(group, on=['date_block_num','sub_type_code'], how='left')\n",
    "martix.head()\n",
    "\n",
    "# 城市-商品 月销量均值\n",
    "group = martix.groupby(['date_block_num','shop_city_code','item_id']).agg({'item_cnt_month':'mean'})\n",
    "group.columns = ['city_item_cnt_month_avg']\n",
    "group.reset_index(inplace=True)\n",
    "martix = martix.merge(group, on=['date_block_num','shop_city_code','item_id'], how='left')\n",
    "martix.head()\n",
    "\n",
    "# 商店类型-商品 月销量均值\n",
    "group = martix.groupby(['date_block_num','shop_type_code','item_id']).agg({'item_cnt_month':'mean'})\n",
    "group.columns = ['shoptype_item_cnt_month_avg']\n",
    "group.reset_index(inplace=True)\n",
    "martix = martix.merge(group, on=['date_block_num','shop_type_code','item_id'], how='left')\n",
    "martix.head()\n",
    "\n",
    "del group\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.添加销量特征的历史特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#添加销量特征的历史特征\n",
    "def lag_feature(df, lags, col):\n",
    "    tmp = df[['date_block_num','shop_id','item_id',col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "    return df\n",
    "\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'item_cnt_month')\n",
    "martix.head()\n",
    "\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'item_cnt_month_avg')\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'shop_cnt_month_avg')\n",
    "martix.head()\n",
    "\n",
    "martix.drop(columns=[ 'item_cnt_month_avg', 'shop_cnt_month_avg'], inplace=True)  # 只保留特征的历史信息\n",
    "gc.collect()\n",
    "\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'cat_cnt_month_avg')\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'shop_cat_cnt_month_avg')\n",
    "martix.head()\n",
    "\n",
    "martix.drop(columns=['cat_cnt_month_avg', 'shop_cat_cnt_month_avg'], inplace=True)\n",
    "\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'itemtype_cnt_month_avg')\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'subtype_cnt_month_avg')\n",
    "martix.head()\n",
    "\n",
    "martix.drop(columns=['itemtype_cnt_month_avg', 'subtype_cnt_month_avg'], inplace=True)\n",
    "\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'city_item_cnt_month_avg')\n",
    "martix = lag_feature(martix, [1,2,3,6,12], 'shoptype_item_cnt_month_avg')\n",
    "martix.head()\n",
    "\n",
    "martix.drop(columns=[ 'city_item_cnt_month_avg','shoptype_item_cnt_month_avg'], inplace=True)\n",
    "martix\n",
    "\n",
    "martix[martix.columns[:20]].isna().any()\n",
    "\n",
    "#使用之前月份的销量，会导致有很多记录缺失信息。需要将这部分缺失信息的记录去掉。\n",
    "\n",
    "#前面延迟了12个月的销量信息，这里就直接把前12个月的记录删除。\n",
    "train_set = martix[martix['date_block_num'] > 11].fillna(0)\n",
    "train_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.对类别特征进行独热编码、类别编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#对类别特征进行独热编码、类别编码，将默认数据类型改为int32和float32，降低模型训练的内存压力\n",
    "for col in train_set.columns:\n",
    "    if col.find('code') >= 0:\n",
    "        train_set[col] = train_set[col].astype(np.int8)\n",
    "    elif train_set[col].dtype == 'float64':\n",
    "        train_set[col] = train_set[col].astype(np.float32)\n",
    "    elif train_set[col].dtype == 'int64':\n",
    "        train_set[col] = train_set[col].astype(np.int16)\n",
    "        \n",
    "train_set['item_type_code'] = train_set['item_type_code'].astype('category')\n",
    "train_set['sub_type_code'] = train_set['sub_type_code'].astype('category')\n",
    "train_set.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.设置训练集验证集测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "#前32个月作为训练集\n",
    "#第33个月作为验证集，34月作为测试集\n",
    "X_train = train_set[train_set['date_block_num'] < 33].drop(columns=['item_cnt_month'])  \n",
    "# 训练集的样本特征\n",
    "Y_train = train_set[train_set['date_block_num'] < 33]['item_cnt_month']  \n",
    "# 训练集的样本标签\n",
    "\n",
    "X_validate = train_set[train_set['date_block_num'] == 33].drop(columns=['item_cnt_month']) \n",
    " # 校对集\n",
    "Y_validate = train_set[train_set['date_block_num'] == 33]['item_cnt_month']\n",
    "\n",
    "X_test = train_set[train_set['date_block_num'] == 34].drop(columns=['item_cnt_month'])  \n",
    "# 测试集\n",
    "\n",
    "del train_set\n",
    "gc.collect()\n",
    "\n",
    "# 把数据加载为模型适合的数据格式\n",
    "train_data = lgb.Dataset(data=X_train, label=Y_train)\n",
    "validate_data = lgb.Dataset(data=X_validate, label=Y_validate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.设置模型参数训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 设置模型训练参数\n",
    "import time\n",
    "ts = time.time()\n",
    "params = {\"objective\" : \"regression\",#目标函数：回归\n",
    "         \"metric\" : \"rmse\", #评估函数均方根误差\n",
    "         'n_estimators':10000, #随机森林中的分类器个数\n",
    "         'early_stopping_rounds':50,#早停循环参数\n",
    "        \"num_leaves\" : 200, #叶子节点数\n",
    "        \"learning_rate\" : 0.01,#学习速率 \n",
    "        \"bagging_fraction\" : 0.9,#建树的样本采样比例\n",
    "        \"feature_fraction\" : 0.3, #建树的特征选择比例\n",
    "        \"bagging_seed\" : 0}#bagging的随机种子数\n",
    "print('Start....', ts)\n",
    "lgb_model = lgb.train(params, train_data, valid_sets=[train_data, validate_data], verbose_eval=1000) \n",
    "print('End...', time.time() - ts)\n",
    "\n",
    "\n",
    "\n",
    "lgb_model.save_model('model_bestscore02.txt')  # 保存模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.特征重要性画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征重要性画图\n",
    "lgb.plot_importance(lgb_model, max_num_features=40, figsize=(12, 8))\n",
    "plt.title(\"Featurertances\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.预测未来销量结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据项目要求，把数据“裁剪”到[0,20]的区间。\n",
    "Y_test = lgb_model.predict(X_test).clip(0, 20)\n",
    "Y_test\n",
    "\n",
    "X_test['item_cnt_month'] = Y_test\n",
    "X_test\n",
    "\n",
    "#将预测结果合并到测试集\n",
    "result = pd.merge(test[['ID', 'shop_id', 'item_id']],X_test[['shop_id','item_id','item_cnt_month']], on=['shop_id', 'item_id'], how='left')\n",
    "result\n",
    "\n",
    "result.isna().any()\n",
    "\n",
    "result[result.shop_id.isin(shop_c_n.columns)]['shop_id'].unique()\n",
    "\n",
    "#前面分析关闭的商店中，有3个商在最近半年里只有最后一个月有销量，推断是新开的商店。\n",
    "#还有一些商品是最近半年都没有销量，推断是已经下架的商品，预测值填为0 \n",
    "result.loc[result.item_id.isin(item_zero), 'item_cnt_month'] = 0\n",
    "result.loc[result.item_id.isin(item_zero), 'item_cnt_month']\n",
    "\n",
    "result[['ID','item_cnt_month']].to_csv('fromfinal01.csv',sep=',',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
